from airflow import DAG
from airflow.operators.python import PythonOperator
import pendulum
import requests
import json
import time
from kafka import KafkaProducer

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
EMPLOYER_IDS = [3529, 78638, 1740]  # –°–±–µ—Ä, –¢-–ë–∞–Ω–∫, –Ø–Ω–¥–µ–∫—Å
VACANCY_TEXT = "–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö"
AREA_ID = 113

# –í–ù–£–¢–†–ò Docker –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –∏–º—è 'kafka' –∏ –ø–æ—Ä—Ç 29092
KAFKA_BOOTSTRAP_SERVERS = ['kafka:29092']
KAFKA_TOPIC = 'raw_vacancies'

HEADERS = {
    "User-Agent": "SkillRadar/Airflow (tvoy_email@gmail.com)"
}

def fetch_hh_data():
    """–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –≤–Ω—É—Ç—Ä–∏ Airflow"""
    print("üöÄ [Airflow] –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö...")
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Kafka (–≤–Ω—É—Ç—Ä–∏ —Å–µ—Ç–∏ Docker)
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_serializer=lambda x: json.dumps(x, ensure_ascii=False).encode('utf-8')
        )
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Kafka: {e}")
        return

    total_sent = 0

    for emp_id in EMPLOYER_IDS:
        print(f"üîé –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–∞–Ω–∏—é {emp_id}...")
        
        # 1. –ü–æ–ª—É—á–∞–µ–º ID –≤–∞–∫–∞–Ω—Å–∏–π
        url = "https://api.hh.ru/vacancies"
        params = {
            "employer_id": emp_id,
            "text": VACANCY_TEXT,
            "area": AREA_ID,
            "per_page": 5, # –ë–µ—Ä–µ–º –ø–æ 5 —à—Ç—É–∫ –¥–ª—è —Ç–µ—Å—Ç–∞
            "page": 0
        }
        
        try:
            resp = requests.get(url, params=params, headers=HEADERS)
            resp.raise_for_status()
            items = resp.json().get('items', [])
            ids = [item['id'] for item in items]
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π: {e}")
            continue

        # 2. –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
        for v_id in ids:
            details_url = f"https://api.hh.ru/vacancies/{v_id}"
            try:
                time.sleep(0.5) # –í–µ–∂–ª–∏–≤–æ—Å—Ç—å
                r_det = requests.get(details_url, headers=HEADERS)
                if r_det.status_code == 200:
                    data = r_det.json()
                    data['search_query'] = VACANCY_TEXT
                    
                    # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Kafka
                    producer.send(KAFKA_TOPIC, value=data)
                    total_sent += 1
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ {v_id}: {e}")

    producer.flush()
    print(f"üèÅ –ì–æ—Ç–æ–≤–æ! –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_sent}")

# --- –û–ü–ò–°–ê–ù–ò–ï DAG (–ò–ù–°–¢–†–£–ö–¶–ò–Ø) ---
with DAG(
    dag_id='hh_vacancy_parser',      # –ò–º—è —Ä–æ–±–æ—Ç–∞ –≤ —Å–ø–∏—Å–∫–µ
    schedule_interval='@daily',      # –ó–∞–ø—É—Å–∫–∞—Ç—å —Ä–∞–∑ –≤ –¥–µ–Ω—å
    start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
    catchup=False,                   # –ù–µ –ø—ã—Ç–∞—Ç—å—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞ –ø—Ä–æ—à–ª—ã–µ –≥–æ–¥—ã
    tags=['skill_radar']
) as dag:

    # –ó–∞–¥–∞—á–∞ 1: –ó–∞–ø—É—Å—Ç–∏—Ç—å Python —Ñ—É–Ω–∫—Ü–∏—é
    task_fetch = PythonOperator(
        task_id='fetch_from_hh',
        python_callable=fetch_hh_data
    )

    task_fetch