# SkillRadar

SkillRadar — ETL-пайплайн для аналитики рынка труда.
Проект собирает вакансии с HH.ru, обогащает их данными, отправляет в Kafka, сохраняет в ClickHouse и предоставляет аналитику через Metabase.
Оркестрация процессов выполняется через Apache Airflow.

## Текущая версия: v13 (Stable)

Проект находится в стадии активной разработки. В версии v13 реализованы следующие ключевые функции:

### 1. Deep Skill Mining (Глубокий анализ навыков)
В отличие от стандартных парсеров, мы не доверяем только тегам HR. Система анализирует полный текст описания вакансии (Description) с помощью регулярных выражений.
- Словарь содержит более 500 технологий (синонимы, версии, сленг, русские названия).
- Распознавание категорий: Backend, Frontend, DevOps, ML, Management, HR и другие.

### 2. Zen Mode (Инкрементальный парсинг)
- "Вежливый" режим сбора данных с динамическими паузами (Anti-Ban).
- Сохранение состояния (State Management): при перезапуске парсер продолжает с места остановки.
- Игнорирование дублей и ранее скачанных вакансий.

### 3. Smart Filtering (Умная фильтрация)
- Многоуровневый Stop-List для отсеивания нецелевых вакансий (водители, курьеры, массовый персонал, продажи).
- Специальные фильтры для банковского сектора (отсеивание операционистов и выездных представителей).

### 4. Infrastructure Stability
- Оптимизация под Docker Desktop и WSL 2.
- Защита от OOM (Out Of Memory) при больших нагрузках.
- Разделение сервисов на микросервисную архитектуру.

---

## Архитектура проекта

- **Airflow 2.7 + Postgres (LocalExecutor)** — оркестрация задач, управление расписанием и зависимостями.
- **Kafka + Zookeeper** — брокер сообщений для буферизации потока вакансий.
- **ClickHouse** — колоночная аналитическая база данных для хранения и быстрых выборок.
- **Metabase** — BI-инструмент для визуализации данных.
- **Docker Compose** — управление контейнеризацией всего стека.

## Требования

- Docker Desktop (или Docker Engine)
- Docker Compose plugin
- Минимум 4GB RAM, выделенных для Docker (рекомендуется 6GB)

---

## Быстрый старт

### 1. Инициализация инфраструктуры

Откройте терминал в корне репозитория и выполните инициализацию базы данных Airflow:

```bash
docker compose up airflow-init

Этот шаг выполняется один раз. Контейнер airflow-init выполнит миграции базы данных и создаст администратора.

После успешной инициализации запустите основной стек:

Bash

docker compose up -d
2. Проверка статуса
Убедитесь, что все контейнеры запущены:

Bash

docker compose ps
Ожидаемое состояние сервисов:

skillradar_airflow_webserver — Up

skillradar_airflow_scheduler — Up

skillradar_postgres — Up (healthy)

skillradar_kafka — Up (healthy)

skillradar_clickhouse — Up (healthy)

skillradar_metabase — Up

3. Доступ к интерфейсам
Airflow: http://localhost:8081

Логин: admin

Пароль: admin

Metabase: http://localhost:3000

ClickHouse:

HTTP API: http://localhost:8123

Native Protocol: localhost:9000

4. Запуск пайплайна
Перейдите в интерфейс Airflow.

Найдите DAG skillradar_zen_v10 (или актуальную версию).

Переведите переключатель слева в положение ON (Unpause).

Запустите DAG вручную кнопкой Trigger DAG (иконка Play), если он не стартовал автоматически по расписанию.

Полезные команды
Остановка проекта
Останавливает контейнеры, но сохраняет данные в томах (volumes):

Bash

docker compose stop
Полная остановка и удаление
Останавливает контейнеры и удаляет их. Данные в томах сохраняются (если не указан флаг -v):

Bash

docker compose down
Просмотр логов
Для отладки процессов Airflow:

Bash

docker compose logs -f airflow-scheduler
Работа с ClickHouse через CLI
Для выполнения SQL-запросов напрямую в контейнере:

Bash

docker exec -it skillradar_clickhouse clickhouse-client
Устранение неполадок
Проблема: Airflow падает с ошибкой Exit Code 137 (OOM) Причина: Нехватка оперативной памяти. Решение: Увеличьте лимит памяти для Docker до 6GB.

Windows (WSL 2): Создайте файл .wslconfig в папке пользователя с параметром memory=6GB.

Mac/Linux: Настройте ресурсы в Docker Dashboard -> Settings -> Resources.

Проблема: "Topic not available" в логах Kafka Причина: Kafka еще не успела создать топик при первом старте. Решение: Это предупреждение можно игнорировать при первом запуске, топик будет создан автоматически.